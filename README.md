# ğŸ§ Nava â€“ Real-Time AI Voice Assistant  
A FastAPI-based real-time voice assistant that supports:  
- Audio â†’ Text (Speech-to-Text)  
- Smart conversation using OpenAI LLM  
- Text â†’ Audio (Text-to-Speech)  
- Bi-directional WebSocket streaming  

Nava is designed for ultra-low-latency voice communication powered by OpenAI.

---

## ğŸ“Œ Features
- ğŸ”Š **Real-time WebSocket voice streaming**
- ğŸ™ï¸ **Speech-to-Text using Whisper**
- ğŸ¤– **Conversational AI using OpenAI LLMs**
- ğŸ”ˆ **Text-to-Speech output (mp3)**
- ğŸ“¡ **Chunked binary audio streaming support**
- ğŸ“ Centralized structured logging with Loguru
- ğŸ”§ Fully Dockerized (Dockerfile included)

---

## ğŸ§± Tech Stack
- **Python 3.11+**
- **FastAPI**
- **WebSockets**
- **OpenAI SDK**
- **SQLAlchemy (async) + Alembic**
- **Loguru**
- **Docker**

---

## âš™ï¸ Environment Variables (`.env`)
Create a `.env` file in the root directory:

```
OPENAI_API_KEY=your_openai_key_here
ENVIRONMENT=development
PROJECT_NAME=nava
VERSION=0.1.0
WEBSOCKET_MAX_SIZE=10000000
LOG_LEVEL=DEBUG
```

---

## ğŸ“¦ Installation (Local Development)

### 1ï¸âƒ£ Create virtual environment
```bash
python3 -m venv .venv
source .venv/bin/activate

pip install -r requirements.txt

uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload

docker build -t nava .

http://127.0.0.1:8000
```
---

## ğŸ”Œ WebSocket Usage Example (CLI)
### Send WAV â†’ Receive MP3

```
cat hello.wav | websocat -b --no-close \
  ws://127.0.0.1:8000/api/v1/ws/voice \
  > answer.mp3

```
---
## ğŸ§  How the Pipeline Works

1. Client sends audio bytes

2. Server transcribes using Whisper

3. LLM generates conversational response

4. Server sends back text

5. TTS generates audio reply

6. Audio is streamed back to the client

---

## ğŸ—‚ Logs

### Log files stored in:

```
logs/app.log

```

---

## ğŸ“„ License

MIT License â€“ Free for personal and commercial use.